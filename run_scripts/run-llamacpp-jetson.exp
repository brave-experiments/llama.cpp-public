#!/usr/bin/expect
# Note:   This script is used to run the llama.cpp models in interactive mode on jetson devices.
# Author: Stefanos Laskaridis (stefanos@brave.com), Kleomenis Katevas (kkatevas@brave.com)


package require json

#exp_internal 1

# Check if an argument is provided
if { $argc != 10 } {
    puts "Usage: $argv0 input_path model_name input_prompts_filename conversation_from conversation_to output_path events_filename iteration cpu n_threads"
    exit 1
}

# config
set timeout -1
set sleep_time 5
set input_path [lindex $argv 0]
set model_name [lindex $argv 1]
set input_prompts_filename [lindex $argv 2]
set conversation_from [expr {int([lindex $argv 3])}]
set conversation_to [expr {int([lindex $argv 4])}]
set output_path [lindex $argv 5]
set events_filename [lindex $argv 6]
set iteration [lindex $argv 7]
set cpu [lindex $argv 8]
set n_threads [lindex $argv 9]
set log_path "$output_path/melt_measurements/llm_output_iter${iteration}_conv${conversation_from}.txt"
log_file $log_path
set measurements "$output_path/melt_measurements/measurements_iter${iteration}_conv${conversation_from}.csv"
set llama_cpp_path "$env(LLAMA_CPP_HOME)"

if {$cpu == "1"} {
    set ngl 0
} else {
    set ngl 100
}

# This is the gguf file generated by melt/src/models/convert.py script.
set model_path "$input_path/$model_name"
set model_dir [file dirname $model_path]
# This is the file generated by melt/src/models/convert.py script.
set extra_args_path "$model_dir/llama_main_args.txt"

# define store metrics function
proc store_metrics {start_time end_time state measurements} {
    set duration [expr {double($end_time - $start_time) / 1000.0}]
    set start_time_epoch [expr {$start_time / 1000.0}]
    set parsed_state [string map {\n \\n} $state]
    exec echo "$start_time_epoch,$duration,\"$parsed_state\"\r" >> "$measurements"
}

# Read the JSON file
set file_data [read [open $input_prompts_filename r]]
set input_prompts [json::json2dict $file_data]

# set range
if {$conversation_to > [expr [llength $input_prompts] -1] } {
    set conversation_to [expr [llength $input_prompts] -1]
}
set input_prompts [lrange $input_prompts $conversation_from $conversation_to]

exec mkdir -p "$output_path/melt_measurements/"
# init measurements file (write csv header)
exec echo "start_date,duration,state\r" > "$measurements"

# Read the file contents
set fd [open $extra_args_path]
set extra_args_str [read $fd]
close $fd

# debug
puts $extra_args_str

# get expect prompt
set expect_prompt ">"
regexp {in-prefix\s+"([^\"]+)"} $extra_args_str match expect_prompt
set expect_prompt [string map {"\\n" ""} $expect_prompt]
# BUG: if gemma not in model name, add newline to expect prompt,
if {![string match "*gemma*" $model_name]} {
    set expect_prompt "\n$expect_prompt"
}

# init variables, this init states are proxy to model loading
set start_time [clock milliseconds]
set state "load_model"

# Use 'list' to construct the command and arguments properly
set command [list spawn $llama_cpp_path/build/bin/main \
    --model $model_path \
    --interactive \
    --log-disable \
    --timings-file $events_filename \
    -t $n_threads \
    -ngl $ngl \
    -e]

# Function to process and append arguments
proc append_args {cmd line} {
    set in_quote 0
    set arg ""
    foreach char [split $line ""] {
        if {$char eq "\""} {
            if {$in_quote} {
                lappend cmd $arg
                set arg ""
            }
            set in_quote [expr !$in_quote]
        } elseif {$in_quote || $char ne " "} {
            append arg $char
        } elseif {[string length $arg] > 0} {
            lappend cmd $arg
            set arg ""
        }
    }
    if {[string length $arg] > 0} {
        lappend cmd $arg
    }
    return $cmd
}

# Append arguments from the file to the command list
foreach line [split $extra_args_str \n] {
    # Trim the line to remove whitespace and backslashes
    set trimmed_line [string trimright $line \\\ ]
    if {[string length $trimmed_line] == 0} {
        continue
    }

    # Process and append the arguments
    set command [append_args $command $trimmed_line]
}

# Append the remaining arguments
lappend command "--interactive-first" "--log-file" "output_raw" "--timings-file" "${events_filename}"

# Execute the command
eval $command

# save pid
set pid [exp_pid]

sleep $sleep_time

# iterate through conversations
foreach conversation $input_prompts {

    # iterate through prompts
    foreach prompt $conversation {

        expect -ex "$expect_prompt" {

            # save metrics of previous prompt (or model load if first iteration)
            set end_time [clock milliseconds]
            store_metrics $start_time $end_time $state $measurements

            sleep $sleep_time

            # save state vars for next iteration and send the prompt
            set state $prompt
            set start_time [clock milliseconds]

            # escape any \n characters in the prompt
            set parsed_prompt [string map {\n \\n} $prompt]
            send "$parsed_prompt\r"
        }
    }

    # TODO: clear context
}

# finish
expect -ex "$expect_prompt" {

    # save last metrics
    set end_time [clock milliseconds]
    store_metrics $start_time $end_time $prompt $measurements

    sleep $sleep_time

    # send SIGINT to report LLM stats and exit
    exec kill -2 $pid
    sleep 60
    expect -ex "Energy events written." {
        puts "Exiting..."
    }

    expect eof
}
